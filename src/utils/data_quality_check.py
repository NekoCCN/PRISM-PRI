"""
æ•°æ®é›†è´¨é‡æ£€æŸ¥å·¥å…·
"""
import yaml
from pathlib import Path
from PIL import Image
import numpy as np
from tqdm import tqdm
from collections import defaultdict
import matplotlib.pyplot as plt


class DataQualityChecker:
    """
    æ•°æ®è´¨é‡æ£€æŸ¥

    æ£€æŸ¥é¡¹ï¼š
    1. å›¾ç‰‡å®Œæ•´æ€§
    2. æ ‡æ³¨å®Œæ•´æ€§
    3. ç±»åˆ«åˆ†å¸ƒ
    4. è¾¹ç•Œæ¡†è´¨é‡
    5. å›¾ç‰‡å°ºå¯¸åˆ†å¸ƒ
    6. é‡å¤å›¾ç‰‡æ£€æµ‹
    """

    def __init__(self, data_yaml):
        with open(data_yaml) as f:
            self.config = yaml.safe_load(f)

        self.data_dir = Path(data_yaml).parent
        self.issues = defaultdict(list)

    def run_checks(self):
        """è¿è¡Œæ‰€æœ‰æ£€æŸ¥"""
        print("ğŸ” å¼€å§‹æ•°æ®è´¨é‡æ£€æŸ¥...")

        checks = [
            ("å›¾ç‰‡å®Œæ•´æ€§", self.check_images),
            ("æ ‡æ³¨å®Œæ•´æ€§", self.check_labels),
            ("ç±»åˆ«åˆ†å¸ƒ", self.check_class_distribution),
            ("è¾¹ç•Œæ¡†è´¨é‡", self.check_bbox_quality),
            ("å›¾ç‰‡å°ºå¯¸", self.check_image_sizes),
            ("é‡å¤æ£€æµ‹", self.check_duplicates),
        ]

        for check_name, check_func in checks:
            print(f"\n[{check_name}æ£€æŸ¥]")
            check_func()

        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report()

    def check_images(self):
        """æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶"""
        train_dir = self.data_dir / self.config['train']
        img_files = list(train_dir.glob('*.jpg')) + list(train_dir.glob('*.png'))

        print(f"   æ‰¾åˆ° {len(img_files)} å¼ å›¾ç‰‡")

        corrupted = []
        for img_path in tqdm(img_files, desc="   æ£€æŸ¥å›¾ç‰‡"):
            try:
                img = Image.open(img_path)
                img.verify()
            except Exception as e:
                corrupted.append(str(img_path))
                self.issues['corrupted_images'].append({
                    'file': str(img_path),
                    'error': str(e)
                })

        if corrupted:
            print(f"   âŒ å‘ç° {len(corrupted)} å¼ æŸåå›¾ç‰‡")
        else:
            print(f"   âœ… æ‰€æœ‰å›¾ç‰‡å®Œæ•´")

    def check_labels(self):
        """æ£€æŸ¥æ ‡æ³¨æ–‡ä»¶"""
        train_dir = self.data_dir / self.config['train']
        label_dir = self.data_dir / self.config['train'].replace('images', 'labels')

        img_files = list(train_dir.glob('*.jpg')) + list(train_dir.glob('*.png'))

        missing_labels = []
        empty_labels = []
        invalid_labels = []

        for img_path in tqdm(img_files, desc="   æ£€æŸ¥æ ‡æ³¨"):
            label_path = label_dir / f"{img_path.stem}.txt"

            # æ£€æŸ¥æ ‡æ³¨æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not label_path.exists():
                missing_labels.append(str(img_path))
                self.issues['missing_labels'].append(str(img_path))
                continue

            # æ£€æŸ¥æ ‡æ³¨æ˜¯å¦ä¸ºç©º
            with open(label_path) as f:
                lines = f.readlines()

            if len(lines) == 0:
                empty_labels.append(str(img_path))
                self.issues['empty_labels'].append(str(img_path))
                continue

            # æ£€æŸ¥æ ‡æ³¨æ ¼å¼
            for line in lines:
                parts = line.strip().split()
                if len(parts) != 5:
                    invalid_labels.append(str(img_path))
                    self.issues['invalid_labels'].append({
                        'file': str(img_path),
                        'line': line
                    })
                    break

        print(f"   ç¼ºå¤±æ ‡æ³¨: {len(missing_labels)}")
        print(f"   ç©ºæ ‡æ³¨: {len(empty_labels)}")
        print(f"   æ— æ•ˆæ ‡æ³¨: {len(invalid_labels)}")

    def check_class_distribution(self):
        """æ£€æŸ¥ç±»åˆ«åˆ†å¸ƒ"""
        label_dir = self.data_dir / self.config['train'].replace('images', 'labels')
        label_files = list(label_dir.glob('*.txt'))

        class_counts = defaultdict(int)

        for label_path in label_files:
            with open(label_path) as f:
                for line in f:
                    cls = int(line.split()[0])
                    class_counts[cls] += 1

        # å¯è§†åŒ–
        plt.figure(figsize=(10, 6))
        classes = sorted(class_counts.keys())
        counts = [class_counts[c] for c in classes]
        names = [self.config['names'][c] for c in classes]

        plt.bar(names, counts)
        plt.xlabel('ç±»åˆ«')
        plt.ylabel('æ ·æœ¬æ•°')
        plt.title('ç±»åˆ«åˆ†å¸ƒ')
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig('class_distribution.png')
        plt.close()

        print(f"   ç±»åˆ«åˆ†å¸ƒå·²ä¿å­˜: class_distribution.png")

        # æ£€æŸ¥ä¸å¹³è¡¡
        max_count = max(counts)
        min_count = min(counts)
        imbalance_ratio = max_count / min_count

        if imbalance_ratio > 10:
            print(f"   âš ï¸  ç±»åˆ«ä¸¥é‡ä¸å¹³è¡¡ (æ¯”ä¾‹: {imbalance_ratio:.1f}:1)")
            self.issues['class_imbalance'] = {
                'ratio': imbalance_ratio,
                'counts': dict(class_counts)
            }

    def check_bbox_quality(self):
        """æ£€æŸ¥è¾¹ç•Œæ¡†è´¨é‡"""
        label_dir = self.data_dir / self.config['train'].replace('images', 'labels')
        label_files = list(label_dir.glob('*.txt'))

        too_small = []
        too_large = []
        invalid_coords = []

        for label_path in label_files:
            with open(label_path) as f:
                for line in f:
                    parts = line.split()
                    cls, cx, cy, w, h = map(float, parts)

                    # æ£€æŸ¥åæ ‡èŒƒå›´
                    if not (0 <= cx <= 1 and 0 <= cy <= 1 and 0 <= w <= 1 and 0 <= h <= 1):
                        invalid_coords.append(str(label_path))
                        self.issues['invalid_coords'].append({
                            'file': str(label_path),
                            'bbox': [cx, cy, w, h]
                        })

                    # æ£€æŸ¥å°ºå¯¸
                    area = w * h
                    if area < 0.001:  # å¤ªå°
                        too_small.append(str(label_path))
                    elif area > 0.9:  # å¤ªå¤§
                        too_large.append(str(label_path))

        print(f"   è¿‡å°è¾¹ç•Œæ¡†: {len(too_small)}")
        print(f"   è¿‡å¤§è¾¹ç•Œæ¡†: {len(too_large)}")
        print(f"   æ— æ•ˆåæ ‡: {len(invalid_coords)}")

    def check_image_sizes(self):
        """æ£€æŸ¥å›¾ç‰‡å°ºå¯¸åˆ†å¸ƒ"""
        train_dir = self.data_dir / self.config['train']
        img_files = list(train_dir.glob('*.jpg')) + list(train_dir.glob('*.png'))

        sizes = []
        for img_path in img_files:
            img = Image.open(img_path)
            sizes.append(img.size)

        widths, heights = zip(*sizes)

        print(f"   å®½åº¦èŒƒå›´: {min(widths)} - {max(widths)}")
        print(f"   é«˜åº¦èŒƒå›´: {min(heights)} - {max(heights)}")
        print(f"   å¹³å‡å°ºå¯¸: {np.mean(widths):.0f} x {np.mean(heights):.0f}")

    def check_duplicates(self):
        """æ£€æµ‹é‡å¤å›¾ç‰‡ï¼ˆåŸºäºhashï¼‰"""
        import hashlib

        train_dir = self.data_dir / self.config['train']
        img_files = list(train_dir.glob('*.jpg')) + list(train_dir.glob('*.png'))

        hashes = {}
        duplicates = []

        for img_path in tqdm(img_files, desc="   è®¡ç®—hash"):
            with open(img_path, 'rb') as f:
                file_hash = hashlib.md5(f.read()).hexdigest()

            if file_hash in hashes:
                duplicates.append((str(img_path), hashes[file_hash]))
                self.issues['duplicates'].append({
                    'file1': str(img_path),
                    'file2': hashes[file_hash]
                })
            else:
                hashes[file_hash] = str(img_path)

        if duplicates:
            print(f"   âš ï¸  å‘ç° {len(duplicates)} å¯¹é‡å¤å›¾ç‰‡")
        else:
            print(f"   âœ… æ— é‡å¤å›¾ç‰‡")

    def generate_report(self):
        """ç”ŸæˆæŠ¥å‘Š"""
        import json

        report_path = 'data_quality_report.json'
        with open(report_path, 'w') as f:
            json.dump(dict(self.issues), f, indent=2)

        print(f"\nğŸ“„ è´¨é‡æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

        # æ€»ç»“
        total_issues = sum(len(v) for v in self.issues.values())
        if total_issues == 0:
            print("âœ… æ•°æ®é›†è´¨é‡è‰¯å¥½ï¼")
        else:
            print(f"âš ï¸  å‘ç° {total_issues} ä¸ªé—®é¢˜")


# ä½¿ç”¨
if __name__ == '__main__':
    checker = DataQualityChecker('dataset/data.yaml')
    checker.run_checks()