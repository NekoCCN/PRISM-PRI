"""
å¸¦å®Œæ•´éªŒè¯çš„è®­ç»ƒè„šæœ¬
"""
import torch
import torch.nn as nn
import torch.optim as optim
from torch.cuda.amp import autocast, GradScaler
from torch.utils.data import DataLoader
from torchvision import transforms
from tqdm import tqdm
import numpy as np
import os
import yaml
from pathlib import Path

from src.dataset import ROIDataset, create_train_val_split
from src.models.refiner import ROIRefinerModel
from src.config import DEVICE, STAGE2_CONFIG, DATASET_DIR, WEIGHTS_DIR
from src.training.losses import OHEMFocalLoss, BalancedL1Loss
from src.training.ema import ModelEMA, SWA
from src.evaluation.evaluator import DetectionEvaluator


class WarmupCosineScheduler:
    """Warmup + Cosineå­¦ä¹ ç‡è°ƒåº¦"""

    def __init__(self, optimizer, warmup_epochs, total_epochs, min_lr=1e-6):
        self.optimizer = optimizer
        self.warmup_epochs = warmup_epochs
        self.total_epochs = total_epochs
        self.min_lr = min_lr
        self.base_lr = optimizer.param_groups[0]['lr']

    def step(self, epoch):
        if epoch < self.warmup_epochs:
            lr = self.base_lr * (epoch + 1) / self.warmup_epochs
        else:
            progress = (epoch - self.warmup_epochs) / (self.total_epochs - self.warmup_epochs)
            lr = self.min_lr + (self.base_lr - self.min_lr) * 0.5 * (1 + np.cos(np.pi * progress))

        for param_group in self.optimizer.param_groups:
            param_group['lr'] = lr
        return lr


def validate(model, val_loader, loss_classifier, loss_regressor, num_classes, epoch):
    """
    éªŒè¯å‡½æ•°

    Returns:
        avg_val_loss, metrics_dict
    """
    model.eval()
    total_cls_loss = 0
    total_reg_loss = 0
    num_batches = 0

    # ç”¨äºè®¡ç®—æŒ‡æ ‡
    all_predictions = []
    all_ground_truths = []

    with torch.no_grad():
        pbar = tqdm(val_loader, desc=f"   éªŒè¯ Epoch {epoch}", ncols=100)

        for roi_images, class_labels, reg_targets in pbar:
            roi_images = roi_images.to(DEVICE)
            class_labels = class_labels.to(DEVICE)
            reg_targets = reg_targets.to(DEVICE)

            cls_mask = class_labels != -2
            pos_mask = class_labels >= 0

            # å‰å‘ä¼ æ’­
            class_logits, bbox_deltas = model(roi_images)

            # åˆ†ç±»æŸå¤±
            if cls_mask.sum() > 0:
                if hasattr(loss_classifier, '__name__') and 'OHEM' in loss_classifier.__class__.__name__:
                    cls_loss, _ = loss_classifier(
                        class_logits[cls_mask],
                        class_labels[cls_mask] + 1
                    )
                else:
                    cls_loss = loss_classifier(
                        class_logits[cls_mask],
                        class_labels[cls_mask] + 1
                    )
            else:
                cls_loss = torch.tensor(0.0, device=DEVICE)

            # å›å½’æŸå¤±
            if pos_mask.sum() > 0:
                bbox_deltas_pos = bbox_deltas[pos_mask]
                class_labels_pos = class_labels[pos_mask]
                indices = torch.arange(len(class_labels_pos), device=DEVICE)
                selected_deltas = bbox_deltas_pos.view(
                    -1, num_classes, 4
                )[indices, class_labels_pos.long()]

                reg_loss = loss_regressor(selected_deltas, reg_targets[pos_mask])
            else:
                reg_loss = torch.tensor(0.0, device=DEVICE)

            total_cls_loss += cls_loss.item() if isinstance(cls_loss, torch.Tensor) else 0
            total_reg_loss += reg_loss.item() if isinstance(reg_loss, torch.Tensor) else 0
            num_batches += 1

            # æ”¶é›†é¢„æµ‹ç»“æœï¼ˆç”¨äºè®¡ç®—æŒ‡æ ‡ï¼‰
            scores = torch.softmax(class_logits, dim=1)
            class_probs, class_preds = torch.max(scores, dim=1)

            for i in range(len(class_labels)):
                if class_labels[i] >= 0:  # åªç»Ÿè®¡æ­£æ ·æœ¬
                    all_predictions.append({
                        'class': class_preds[i].item(),
                        'confidence': class_probs[i].item(),
                        'bbox': [0, 0, 1, 1]  # ç®€åŒ–
                    })
                    all_ground_truths.append({
                        'class': class_labels[i].item(),
                        'bbox': [0, 0, 1, 1]
                    })

            pbar.set_postfix({
                'cls_loss': f'{cls_loss.item():.3f}' if isinstance(cls_loss, torch.Tensor) else '0',
                'reg_loss': f'{reg_loss.item():.3f}' if isinstance(reg_loss, torch.Tensor) else '0'
            })

    avg_cls_loss = total_cls_loss / max(num_batches, 1)
    avg_reg_loss = total_reg_loss / max(num_batches, 1)
    avg_total_loss = avg_cls_loss + avg_reg_loss

    # è®¡ç®—å‡†ç¡®ç‡ï¼ˆç®€å•ç‰ˆï¼‰
    if len(all_predictions) > 0:
        correct = sum(1 for p, g in zip(all_predictions, all_ground_truths)
                      if p['class'] == g['class'])
        accuracy = correct / len(all_predictions)
    else:
        accuracy = 0.0

    metrics = {
        'val_cls_loss': avg_cls_loss,
        'val_reg_loss': avg_reg_loss,
        'val_total_loss': avg_total_loss,
        'val_accuracy': accuracy
    }

    return avg_total_loss, metrics


def run_training_with_validation():
    """å¸¦å®Œæ•´éªŒè¯çš„è®­ç»ƒ"""
    print("=" * 80)
    print("ğŸš€ é˜¶æ®µäºŒè®­ç»ƒ - å¸¦éªŒè¯ç‰ˆæœ¬")
    print("=" * 80)

    # ==================== æ•°æ®å‡†å¤‡ ====================
    print("\n" + "=" * 80)
    print("ğŸ“¦ æ­¥éª¤1: å‡†å¤‡æ•°æ®é›†ï¼ˆTrain + Valï¼‰")
    print("=" * 80)

    # æ£€æŸ¥æ˜¯å¦å·²æœ‰åˆ’åˆ†
    train_proposals = Path(STAGE2_CONFIG['proposals_json']).parent / 'proposals_train.json'
    val_proposals = Path(STAGE2_CONFIG['proposals_json']).parent / 'proposals_val.json'

    if not train_proposals.exists() or not val_proposals.exists():
        print("   æœªæ‰¾åˆ°è®­ç»ƒ/éªŒè¯é›†åˆ’åˆ†ï¼Œæ­£åœ¨åˆ›å»º...")
        train_proposals, val_proposals = create_train_val_split(
            STAGE2_CONFIG['proposals_json'],
            val_ratio=0.2,
            seed=42
        )

    # è®­ç»ƒé›†å¢å¼º
    train_transform = transforms.Compose([
        transforms.Resize((STAGE2_CONFIG['roi_size'], STAGE2_CONFIG['roi_size'])),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomVerticalFlip(p=0.5),
        transforms.RandomRotation(15),
        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),
        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

    # éªŒè¯é›†æ— å¢å¼º
    val_transform = transforms.Compose([
        transforms.Resize((STAGE2_CONFIG['roi_size'], STAGE2_CONFIG['roi_size'])),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

    train_dataset = ROIDataset(
        proposals_file=str(train_proposals),
        transform=train_transform,
        positive_thresh=STAGE2_CONFIG['positive_iou_thresh'],
        negative_thresh=STAGE2_CONFIG['negative_iou_thresh']
    )

    val_dataset = ROIDataset(
        proposals_file=str(val_proposals),
        transform=val_transform,
        positive_thresh=STAGE2_CONFIG['positive_iou_thresh'],
        negative_thresh=STAGE2_CONFIG['negative_iou_thresh']
    )

    train_loader = DataLoader(
        train_dataset,
        batch_size=STAGE2_CONFIG['batch_size'],
        shuffle=True,
        num_workers=4,
        pin_memory=True,
        drop_last=True
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=STAGE2_CONFIG['batch_size'],
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )

    print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆ")
    print(f"   - è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
    print(f"   - éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬")
    print(f"   - è®­ç»ƒbatches: {len(train_loader)}")
    print(f"   - éªŒè¯batches: {len(val_loader)}")

    # ==================== æ¨¡å‹åˆå§‹åŒ– ====================
    print("\n" + "=" * 80)
    print("ğŸ—ï¸  æ­¥éª¤2: åˆå§‹åŒ–æ¨¡å‹")
    print("=" * 80)

    with open(os.path.join(DATASET_DIR, 'data.yaml'), 'r') as f:
        num_classes = yaml.safe_load(f)['nc']

    model = ROIRefinerModel(device=DEVICE)
    ema = ModelEMA(model, decay=0.9999)
    swa = SWA(model)
    swa_start_epoch = int(STAGE2_CONFIG['epochs'] * 0.75)

    print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")

    # ==================== æŸå¤±å’Œä¼˜åŒ–å™¨ ====================
    print("\n" + "=" * 80)
    print("ğŸ“Š æ­¥éª¤3: é…ç½®è®­ç»ƒç»„ä»¶")
    print("=" * 80)

    loss_classifier = OHEMFocalLoss(alpha=0.25, gamma=2.0, ohem_ratio=0.7)
    loss_regressor = BalancedL1Loss(alpha=0.5, gamma=1.5, beta=1.0)

    optimizer = optim.AdamW(
        filter(lambda p: p.requires_grad, model.parameters()),
        lr=STAGE2_CONFIG['learning_rate'],
        weight_decay=1e-4,
        betas=(0.9, 0.999)
    )

    scheduler = WarmupCosineScheduler(
        optimizer,
        warmup_epochs=5,
        total_epochs=STAGE2_CONFIG['epochs'],
        min_lr=1e-6
    )

    scaler = GradScaler()

    # ==================== è®­ç»ƒå¾ªç¯ ====================
    print("\n" + "=" * 80)
    print("ğŸ¯ æ­¥éª¤4: å¼€å§‹è®­ç»ƒï¼ˆå¸¦éªŒè¯ï¼‰")
    print("=" * 80)

    best_val_loss = float('inf')
    best_val_acc = 0.0
    no_improve_count = 0
    patience = 15

    history = {
        'train_loss': [],
        'val_loss': [],
        'val_accuracy': [],
        'learning_rate': []
    }

    for epoch in range(STAGE2_CONFIG['epochs']):
        # ========== è®­ç»ƒé˜¶æ®µ ==========
        model.train()
        epoch_train_loss = 0
        num_train_batches = 0

        current_lr = scheduler.step(epoch)

        pbar = tqdm(
            train_loader,
            desc=f"è®­ç»ƒ Epoch {epoch + 1}/{STAGE2_CONFIG['epochs']}",
            ncols=120
        )

        for roi_images, class_labels, reg_targets in pbar:
            roi_images = roi_images.to(DEVICE)
            class_labels = class_labels.to(DEVICE)
            reg_targets = reg_targets.to(DEVICE)

            cls_mask = class_labels != -2
            pos_mask = class_labels >= 0

            with autocast():
                class_logits, bbox_deltas = model(roi_images)

                # åˆ†ç±»æŸå¤±
                if cls_mask.sum() > 0:
                    cls_loss, _ = loss_classifier(
                        class_logits[cls_mask],
                        class_labels[cls_mask] + 1
                    )
                else:
                    cls_loss = torch.tensor(0.0, device=DEVICE)

                # å›å½’æŸå¤±
                if pos_mask.sum() > 0:
                    bbox_deltas_pos = bbox_deltas[pos_mask]
                    class_labels_pos = class_labels[pos_mask]
                    indices = torch.arange(len(class_labels_pos), device=DEVICE)
                    selected_deltas = bbox_deltas_pos.view(
                        -1, num_classes, 4
                    )[indices, class_labels_pos.long()]

                    reg_loss = loss_regressor(selected_deltas, reg_targets[pos_mask])
                else:
                    reg_loss = torch.tensor(0.0, device=DEVICE)

                total_loss = cls_loss + reg_loss

            optimizer.zero_grad()
            scaler.scale(total_loss).backward()
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            scaler.step(optimizer)
            scaler.update()

            ema.update(model)
            if epoch >= swa_start_epoch:
                swa.update(model)

            epoch_train_loss += total_loss.item()
            num_train_batches += 1

            pbar.set_postfix({
                'Loss': f'{total_loss.item():.3f}',
                'LR': f'{current_lr:.2e}'
            })

        avg_train_loss = epoch_train_loss / num_train_batches

        # ========== éªŒè¯é˜¶æ®µ ==========
        print(f"\nğŸ“Š è¿è¡ŒéªŒè¯...")
        avg_val_loss, val_metrics = validate(
            model, val_loader, loss_classifier, loss_regressor, num_classes, epoch + 1
        )

        # ========== è®°å½•ä¸æ‰“å° ==========
        history['train_loss'].append(avg_train_loss)
        history['val_loss'].append(avg_val_loss)
        history['val_accuracy'].append(val_metrics['val_accuracy'])
        history['learning_rate'].append(current_lr)

        print(f"\nğŸ“ˆ Epoch {epoch + 1} ç»“æœ:")
        print(f"   è®­ç»ƒæŸå¤±: {avg_train_loss:.4f}")
        print(f"   éªŒè¯æŸå¤±: {avg_val_loss:.4f}")
        print(f"   éªŒè¯å‡†ç¡®ç‡: {val_metrics['val_accuracy']:.4f}")
        print(f"   å­¦ä¹ ç‡: {current_lr:.2e}")

        # ========== æ¨¡å‹ä¿å­˜ ==========
        # ä¿å­˜æœ€ä½³éªŒè¯æŸå¤±æ¨¡å‹
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            no_improve_count = 0

            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': best_val_loss,
                'val_acc': val_metrics['val_accuracy'],
            }, STAGE2_CONFIG['weights_path'].replace('.pth', '_best_val_loss.pth'))

            print(f"   âœ… æœ€ä½³éªŒè¯æŸå¤±æ¨¡å‹å·²ä¿å­˜ (Loss: {best_val_loss:.4f})")
        else:
            no_improve_count += 1

        # ä¿å­˜æœ€ä½³éªŒè¯å‡†ç¡®ç‡æ¨¡å‹
        if val_metrics['val_accuracy'] > best_val_acc:
            best_val_acc = val_metrics['val_accuracy']

            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': avg_val_loss,
                'val_acc': best_val_acc,
            }, STAGE2_CONFIG['weights_path'].replace('.pth', '_best_val_acc.pth'))

            print(f"   âœ… æœ€ä½³éªŒè¯å‡†ç¡®ç‡æ¨¡å‹å·²ä¿å­˜ (Acc: {best_val_acc:.4f})")

        # æ—©åœ
        if no_improve_count >= patience:
            print(f"\nâš ï¸  éªŒè¯æŸå¤±è¿ç»­{patience}ä¸ªepochæœªæ”¹å–„ï¼Œè§¦å‘æ—©åœ")
            break

    # ==================== è®­ç»ƒå®Œæˆ ====================
    print("\n" + "=" * 80)
    print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
    print("=" * 80)
    print(f"\nğŸ“Š æœ€ç»ˆç»“æœ:")
    print(f"   æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
    print(f"   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}")

    # ä¿å­˜è®­ç»ƒå†å²
    import json
    with open('training_history.json', 'w') as f:
        json.dump(history, f, indent=2)

    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    plot_training_curves(history)

    print(f"\nğŸ’¾ æ¨¡å‹å·²ä¿å­˜:")
    print(f"   - æœ€ä½³éªŒè¯æŸå¤±: {STAGE2_CONFIG['weights_path'].replace('.pth', '_best_val_loss.pth')}")
    print(f"   - æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {STAGE2_CONFIG['weights_path'].replace('.pth', '_best_val_acc.pth')}")


def plot_training_curves(history):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
    import matplotlib.pyplot as plt

    fig, axes = plt.subplots(2, 1, figsize=(10, 10))

    # æŸå¤±æ›²çº¿
    axes[0].plot(history['train_loss'], label='Train Loss')
    axes[0].plot(history['val_loss'], label='Val Loss')
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Loss')
    axes[0].set_title('Training and Validation Loss')
    axes[0].legend()
    axes[0].grid(True)

    # å‡†ç¡®ç‡æ›²çº¿
    axes[1].plot(history['val_accuracy'], label='Val Accuracy', color='green')
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('Accuracy')
    axes[1].set_title('Validation Accuracy')
    axes[1].legend()
    axes[1].grid(True)

    plt.tight_layout()
    plt.savefig('training_curves.png', dpi=150)
    plt.close()

    print("   ğŸ“ˆ è®­ç»ƒæ›²çº¿å·²ä¿å­˜: training_curves.png")


if __name__ == '__main__':
    run_training_with_validation()